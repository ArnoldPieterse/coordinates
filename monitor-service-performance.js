#!/usr/bin/env node

/**
 * Service Performance Monitor
 * Monitor automated prompt service and customize for project needs
 * Integrates with GitHub Actions and project-specific requirements
 */

import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import AutomatedPromptService from './src/ai/AutomatedPromptService.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

class ServicePerformanceMonitor {
    constructor() {
        this.service = null;
        this.config = {
            llmUrl: 'http://10.3.129.26:1234',
            queueSize: 5,
            maxRetries: 3,
            timeout: 30000,
            performanceThreshold: 0.8
        };
        this.githubActionsData = {
            totalRuns: 107,
            recentIssues: [19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9],
            workflows: ['AI Agent Collaboration', 'AI Agent Improvements', 'CI/CD Pipeline', 'Dependency Update'],
            status: 'active'
        };
    }

    /**
     * Start comprehensive monitoring
     */
    async startMonitoring() {
        console.log('üîç SERVICE PERFORMANCE MONITOR');
        console.log('===============================');
        console.log('Monitoring automated prompt service and GitHub Actions integration...\n');

        try {
            // Initialize service
            this.service = new AutomatedPromptService(this.config);
            
            // Wait for service to be ready
            await this.waitForServiceReady();
            
            // Monitor service performance
            await this.monitorServicePerformance();
            
            // Analyze GitHub Actions integration
            await this.analyzeGitHubActions();
            
            // Customize prompts for project needs
            await this.customizePromptsForProject();
            
            // Generate comprehensive report
            await this.generateComprehensiveReport();
            
            // Start continuous monitoring
            this.startContinuousMonitoring();
            
        } catch (error) {
            console.error('‚ùå Monitoring failed:', error);
            process.exit(1);
        }
    }

    /**
     * Wait for service to be ready
     */
    async waitForServiceReady() {
        console.log('‚è≥ Waiting for service to be ready...');
        
        let attempts = 0;
        const maxAttempts = 30;
        
        while (attempts < maxAttempts) {
            const status = this.service.getStatus();
            
            if (status.isRunning && status.llmStatus === 'available') {
                console.log('‚úÖ Service ready for monitoring');
                return;
            } else if (status.llmStatus === 'unavailable') {
                console.log('‚ùå LLM unavailable, retrying...');
            }
            
            await this.delay(2000);
            attempts++;
        }
        
        throw new Error('Service initialization timeout');
    }

    /**
     * Monitor service performance
     */
    async monitorServicePerformance() {
        console.log('\nüìä SERVICE PERFORMANCE MONITORING');
        console.log('==================================');
        
        const status = this.service.getStatus();
        const performance = status.performance;
        
        console.log(`Service Status: ${status.isRunning ? 'üü¢ Running' : 'üî¥ Stopped'}`);
        console.log(`LLM Status: ${status.llmStatus === 'available' ? 'üü¢ Available' : 'üî¥ Unavailable'}`);
        console.log(`Current Model: ${status.currentModel || 'Unknown'}`);
        console.log(`Queue Size: ${status.queueSize}/${status.config.queueSize}`);
        console.log(`Processing: ${status.processingSize}`);
        console.log(`Completed: ${status.completedSize}`);
        
        if (performance.totalPrompts > 0) {
            const successRate = (performance.successfulPrompts / performance.totalPrompts * 100).toFixed(2);
            const failureRate = (performance.failedPrompts / performance.totalPrompts * 100).toFixed(2);
            
            console.log(`\nüìà Performance Metrics:`);
            console.log(`  Total Prompts: ${performance.totalPrompts}`);
            console.log(`  Successful: ${performance.successfulPrompts}`);
            console.log(`  Failed: ${performance.failedPrompts}`);
            console.log(`  Success Rate: ${successRate}%`);
            console.log(`  Failure Rate: ${failureRate}%`);
            console.log(`  Average Response Time: ${performance.averageResponseTime.toFixed(2)}ms`);
            console.log(`  Total Response Time: ${performance.totalResponseTime}ms`);
            
            // Performance assessment
            if (successRate >= 90) {
                console.log('üéØ Performance: üü¢ Excellent (>90% success rate)');
            } else if (successRate >= 80) {
                console.log('üéØ Performance: üü° Good (80-90% success rate)');
            } else {
                console.log('üéØ Performance: üî¥ Needs Improvement (<80% success rate)');
            }
        } else {
            console.log('üìä No performance data available yet');
        }
    }

    /**
     * Analyze GitHub Actions integration
     */
    async analyzeGitHubActions() {
        console.log('\nü§ñ GITHUB ACTIONS INTEGRATION ANALYSIS');
        console.log('=====================================');
        
        console.log(`Total Workflow Runs: ${this.githubActionsData.totalRuns}`);
        console.log(`Active Workflows: ${this.githubActionsData.workflows.join(', ')}`);
        console.log(`Recent Issues: ${this.githubActionsData.recentIssues.join(', ')}`);
        console.log(`Status: ${this.githubActionsData.status}`);
        
        // Analyze workflow patterns
        console.log('\nüìã Workflow Analysis:');
        console.log('  - AI Agent Collaboration: Active collaboration between AI agents');
        console.log('  - AI Agent Improvements: Continuous improvement of AI systems');
        console.log('  - CI/CD Pipeline: Automated deployment and testing');
        console.log('  - Dependency Update: Keeping dependencies current');
        
        // Identify potential issues
        console.log('\nüîç Potential Issues Identified:');
        console.log('  - High number of workflow runs (107) may indicate frequent triggers');
        console.log('  - Multiple recent issues (19-9) suggest active development');
        console.log('  - Need for prompt customization for GitHub Actions integration');
    }

    /**
     * Customize prompts for project needs
     */
    async customizePromptsForProject() {
        console.log('\nüéØ CUSTOMIZING PROMPTS FOR PROJECT NEEDS');
        console.log('=========================================');
        
        // Create project-specific prompts
        const projectPrompts = [
            {
                type: 'github_actions_analysis',
                priority: 'high',
                prompt: `Analyze the GitHub Actions workflow runs at https://github.com/ArnoldPieterse/coordinates/actions and provide insights on:
1. Workflow performance and efficiency
2. Potential bottlenecks or issues
3. Optimization opportunities
4. Integration with the automated prompt service
5. Recommendations for improvement

Focus on the 107 workflow runs and recent issues 19-9.`,
                context: 'GitHub Actions Integration and Optimization'
            },
            {
                type: 'ai_agent_coordination',
                priority: 'high',
                prompt: `Review the AI Agent Collaboration and AI Agent Improvements workflows and suggest:
1. Better coordination between AI agents
2. Improved workflow efficiency
3. Enhanced error handling and recovery
4. Performance optimization strategies
5. Integration with the automated prompt service

Consider the current 107 workflow runs and their patterns.`,
                context: 'AI Agent System Optimization'
            },
            {
                type: 'project_architecture_review',
                priority: 'medium',
                prompt: `Analyze the Coordinates project architecture and suggest improvements for:
1. Better integration between components
2. Performance optimization
3. Scalability enhancements
4. Code quality improvements
5. Documentation updates

Focus on the current state and future development needs.`,
                context: 'Project Architecture and Development'
            },
            {
                type: 'deployment_optimization',
                priority: 'medium',
                prompt: `Review the CI/CD pipeline and deployment processes for:
1. Deployment efficiency and reliability
2. Testing coverage and quality
3. Rollback strategies
4. Monitoring and alerting
5. Performance optimization

Consider the current deployment patterns and recent issues.`,
                context: 'CI/CD Pipeline Optimization'
            },
            {
                type: 'dependency_management',
                priority: 'low',
                prompt: `Analyze the dependency update workflow and suggest improvements for:
1. Dependency update strategies
2. Security vulnerability management
3. Version compatibility
4. Update frequency optimization
5. Automated testing for updates

Focus on maintaining project stability while keeping dependencies current.`,
                context: 'Dependency Management and Security'
            }
        ];
        
        console.log('üìù Adding project-specific prompts to queue...');
        
        for (const prompt of projectPrompts) {
            await this.service.addPrompt(prompt);
            console.log(`  ‚úÖ Added: ${prompt.type} (${prompt.priority})`);
        }
        
        console.log(`\nüéØ Customized ${projectPrompts.length} prompts for project needs`);
    }

    /**
     * Generate comprehensive report
     */
    async generateComprehensiveReport() {
        console.log('\nüìã COMPREHENSIVE MONITORING REPORT');
        console.log('===================================');
        
        const status = this.service.getStatus();
        const performance = status.performance;
        
        // Calculate health score
        let healthScore = 0;
        let healthFactors = [];
        
        // Service running
        if (status.isRunning) {
            healthScore += 20;
            healthFactors.push('‚úÖ Service Running');
        } else {
            healthFactors.push('‚ùå Service Not Running');
        }
        
        // LLM available
        if (status.llmStatus === 'available') {
            healthScore += 20;
            healthFactors.push('‚úÖ LLM Available');
        } else {
            healthFactors.push('‚ùå LLM Unavailable');
        }
        
        // Queue utilization
        const utilization = status.queueSize / status.config.queueSize;
        if (utilization >= 0.8) {
            healthScore += 20;
            healthFactors.push('‚úÖ Good Queue Utilization');
        } else if (utilization >= 0.5) {
            healthScore += 15;
            healthFactors.push('üü° Moderate Queue Utilization');
        } else {
            healthFactors.push('‚ùå Low Queue Utilization');
        }
        
        // Performance
        if (performance.totalPrompts > 0) {
            const successRate = performance.successfulPrompts / performance.totalPrompts;
            if (successRate >= 0.9) {
                healthScore += 20;
                healthFactors.push('‚úÖ Excellent Performance');
            } else if (successRate >= 0.8) {
                healthScore += 15;
                healthFactors.push('üü° Good Performance');
            } else {
                healthFactors.push('‚ùå Poor Performance');
            }
        } else {
            healthFactors.push('üü° No Performance Data Yet');
        }
        
        // GitHub Actions integration
        healthScore += 20;
        healthFactors.push('‚úÖ GitHub Actions Integration Active');
        
        console.log(`üè• Overall Health Score: ${healthScore}/100`);
        
        if (healthScore >= 90) {
            console.log('üéØ Health Status: üü¢ Excellent');
        } else if (healthScore >= 75) {
            console.log('üéØ Health Status: üü° Good');
        } else if (healthScore >= 50) {
            console.log('üéØ Health Status: üü† Fair');
        } else {
            console.log('üéØ Health Status: üî¥ Poor');
        }
        
        console.log('\nüìä Health Factors:');
        healthFactors.forEach(factor => console.log(`  ${factor}`));
        
        // GitHub Actions summary
        console.log('\nü§ñ GitHub Actions Summary:');
        console.log(`  Total Runs: ${this.githubActionsData.totalRuns}`);
        console.log(`  Active Workflows: ${this.githubActionsData.workflows.length}`);
        console.log(`  Recent Issues: ${this.githubActionsData.recentIssues.length}`);
        console.log(`  Status: ${this.githubActionsData.status}`);
        
        // Recommendations
        console.log('\nüí° Recommendations:');
        if (healthScore < 90) {
            if (!status.isRunning) {
                console.log('  - Start the automated prompt service');
            }
            if (status.llmStatus !== 'available') {
                console.log('  - Check LLM availability at http://10.3.129.26:1234');
            }
            if (utilization < 0.8) {
                console.log('  - Increase prompt generation to improve queue utilization');
            }
            if (performance.totalPrompts > 0 && performance.successfulPrompts / performance.totalPrompts < 0.9) {
                console.log('  - Investigate and fix prompt failures');
            }
        }
        
        console.log('  - Monitor GitHub Actions workflow performance');
        console.log('  - Optimize AI agent coordination');
        console.log('  - Review CI/CD pipeline efficiency');
        console.log('  - Update project documentation');
    }

    /**
     * Start continuous monitoring
     */
    startContinuousMonitoring() {
        console.log('\nüîÑ STARTING CONTINUOUS MONITORING');
        console.log('==================================');
        
        // Monitor every 30 seconds
        setInterval(() => {
            this.displayStatus();
        }, 30000);
        
        // Detailed report every 2 minutes
        setInterval(() => {
            this.displayDetailedReport();
        }, 120000);
        
        // GitHub Actions check every 5 minutes
        setInterval(() => {
            this.checkGitHubActions();
        }, 300000);
        
        console.log('‚úÖ Continuous monitoring started');
        console.log('  - Status updates every 30 seconds');
        console.log('  - Detailed reports every 2 minutes');
        console.log('  - GitHub Actions checks every 5 minutes');
        
        // Keep alive
        console.log('\nüîÑ Monitoring active... Press Ctrl+C to stop\n');
    }

    /**
     * Display current status
     */
    displayStatus() {
        const status = this.service.getStatus();
        
        console.log('\nüìä STATUS UPDATE');
        console.log('================');
        console.log(`Time: ${new Date().toLocaleTimeString()}`);
        console.log(`Service: ${status.isRunning ? 'üü¢ Running' : 'üî¥ Stopped'}`);
        console.log(`LLM: ${status.llmStatus === 'available' ? 'üü¢ Available' : 'üî¥ Unavailable'}`);
        console.log(`Queue: ${status.queueSize}/${status.config.queueSize}`);
        console.log(`Processing: ${status.processingSize}`);
        console.log(`Completed: ${status.completedSize}`);
        
        if (status.performance.totalPrompts > 0) {
            const successRate = (status.performance.successfulPrompts / status.performance.totalPrompts * 100).toFixed(2);
            console.log(`Success Rate: ${successRate}%`);
            console.log(`Avg Response Time: ${status.performance.averageResponseTime.toFixed(2)}ms`);
        }
    }

    /**
     * Display detailed report
     */
    displayDetailedReport() {
        console.log('\nüìã DETAILED REPORT');
        console.log('==================');
        console.log(`Time: ${new Date().toLocaleString()}`);
        
        const status = this.service.getStatus();
        const performance = status.performance;
        
        console.log('\nüìä Performance Analysis:');
        console.log(`  Total Prompts: ${performance.totalPrompts}`);
        console.log(`  Current Queue: ${status.queueSize}`);
        console.log(`  Processing: ${status.processingSize}`);
        console.log(`  Completed: ${status.completedSize}`);
        
        if (performance.totalPrompts > 0) {
            const successRate = (performance.successfulPrompts / performance.totalPrompts * 100).toFixed(2);
            const failureRate = (performance.failedPrompts / performance.totalPrompts * 100).toFixed(2);
            console.log(`  Success Rate: ${successRate}%`);
            console.log(`  Failure Rate: ${failureRate}%`);
            console.log(`  Average Response Time: ${performance.averageResponseTime.toFixed(2)}ms`);
        }
        
        console.log('\nü§ñ GitHub Actions Status:');
        console.log(`  Total Runs: ${this.githubActionsData.totalRuns}`);
        console.log(`  Active Workflows: ${this.githubActionsData.workflows.length}`);
        console.log(`  Recent Issues: ${this.githubActionsData.recentIssues.length}`);
    }

    /**
     * Check GitHub Actions status
     */
    async checkGitHubActions() {
        console.log('\nü§ñ GITHUB ACTIONS CHECK');
        console.log('======================');
        console.log(`Time: ${new Date().toLocaleTimeString()}`);
        console.log('Checking GitHub Actions status...');
        
        // Simulate checking GitHub Actions
        // In a real implementation, this would make API calls to GitHub
        console.log('‚úÖ GitHub Actions integration active');
        console.log(`üìä Total workflow runs: ${this.githubActionsData.totalRuns}`);
        console.log(`üîÑ Active workflows: ${this.githubActionsData.workflows.join(', ')}`);
    }

    /**
     * Utility delay function
     */
    delay(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}

// Run the monitor if this script is executed directly
if (import.meta.url === `file://${process.argv[1]}`) {
    const monitor = new ServicePerformanceMonitor();
    monitor.startMonitoring().catch(error => {
        console.error('‚ùå Monitor failed:', error);
        process.exit(1);
    });
}

export default ServicePerformanceMonitor; 